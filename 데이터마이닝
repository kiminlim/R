# 6. 인과(상관)관계 검정 (247~)

head(iris)
cor(iris[,1:4]) # 4변수들 간에 어떤 관계가 있는지, 상관계수!
# > 이게 상관행렬임.(대칭임, 삼각형의 한 면만 봐도 됨)
# >> Sepal.Length가 길어지면 Petal.Length Petal.Width 도 커짐을 알 수 있어
# >> 반대로 Sepal.Width가 길어지면  Petal.Length Petal.Width는 줄어들 것으로 보여
##  > 여기서 이 '상관계수를 보고', 이 변수들의 수치를 알면, 종을 분류할 수 있지 않을 까 해서 보는거임.

cor.test(iris$Sepal.Length, iris$Sepal.Width) # 이 두개가 상관관계가 있는지 검정해보자
# cor는 -0.1175698 , p-value = 0.1519이니(귀무가설(관계없음) 기각 못함) 둘은 관계가 없네~ 
# 근데 사실 상관계수는 잘 검정하지 않음
# 그냥 어떤 값을 같는지, 서로 어떤 관계가 있는지.


  ##< 6장. 데이터 마이닝 >##

# 너 뭐 궁금하다매> 그러면 그걸 할 수 있는 데이터가 있어야해
# 통계는 > 궁금하면 > 자료수짐(샘플링/실험계획법)
# 데이터마이닝은 > 자료가 그냥 있어 > 그걸로 의미있는 결과를 내는 것
# >>예를들어 기업이 가지고있는 데이터, 물어보면 그거 그냥 pdf로 바꿔놨는데요? 한 3테라쯤 될텐데
# 녹음도 해놨는데 한 하드디스크 몇십개는 될껄요? 이래. 그걸 정제해서 결과를 내야해
# 데이터마이닝하는 사람을 데이터마이너라고 하는데 거의 다 통계학 박사야. (알아야할게 많으니 학부로는 안끼워준다는 얘기ㅠㅠ)
# 이쪽하면서 가장 힘들어 하는게 통계공부야. 근데 우리가 전공이 통계잖아. 

# 회귀분석 모형 실험
alpha <- 10.8
beta <- 3.7

x <- 1:30
y1 <- alpha + beta*x + rnorm(30,0,100) # 오차항을 rnorm(30,0,100)로 난수로 갖다줌
y1 # 이렇게 모의실험을 해볼 수 있어
plot(x,y1) 


y <- alpha + beta*x + rnorm(30,0,10) # 오차항을 rnorm(30,0,10)로 바꿔줌
y 
plot(x,y) # 이러면 패턴이 있는걸 볼 수 있어
# 통계학은 데마는 말하는 방식은 달라도 결국 하고싶은건 같아
# 데마는 룰을 찾자! 알고리즘을 찾자! 이렇게 말하고
# 통계학
rst <- lm(y~x)
rst # 룰을 찾았더니 이렇더래. 개네는 룰이라 표현해
summary(rst) # 데마하는 애들은 억세스한다고 하고 이벨류한다고 표현해
# > 이 룰은 평가를 해보니 의미가 있는 룰입니다. 하는거야
# 데마하는 애들도 몰라. 언어가 달라 데마쪽이랑 통계쪽이랑. 처음엔 헷갈리는데 교수님은 익숙해지심ㅋㅋ
pred <- predict(rst) # 근데 예측도 해보고 싶으니 예측
plot(x,y) # 원래 데이터 산점도 그리고
lines(pred) # 예측한 값을 선으로 그려서 비교해볼 수 있어 
# > 실제 현실세계에서도 이랬으면 좋겠는데,, 현실은
plot(x,y1) 
lines(pred) # 현실은 이거야 ㅋㅋ

rst1 <- lm(y1~x)
summary(rst1) # 결정계수도 낮고, x도 피값이 커ㅜㅜ
# > 이런 규칙이 못마땅하다는 거지
# >>> 그래서 나온 방안이 인공신경망이라는거야. (오오 이거 하려다 못한건데)
# 이게 인공신경망이 딥러닝의 반이야. 인공신경망은 회귀분석의 반이고
# 그러면 우리는 딥러닝의 반은 하고 졸업하는거. 나머지 30은 석사때 하면 되겠네ㅋㅋ 
